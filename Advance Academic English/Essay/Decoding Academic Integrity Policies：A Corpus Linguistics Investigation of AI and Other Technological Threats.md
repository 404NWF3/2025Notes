**Abstract**
This study presents a corpus analysis of academic integrity policies from Higher
Education Institutions (HEIs) worldwide, exploring how they address the issues
posed by technological threats, such as Automated Paraphrasing Tools and
generative-artificial intelligence tools, such as ChatGPT. The analysis of 142 policies
conducted in November and December 2022, and May 2023 reveals a gap regarding
the mention of AI and associated technologies in the available academic integrity
policies. Despite the growing prevalence of these tools in the 6-month period
since the release of ChatGPT, no HEIs had produced revised academic integrity
policies. Content analysis of 53 guidance documents produced by HEIs suggests
an overall positive focus of Gen AI tools, yet advises caution. This study suggests
a modification to Bretag et al.’s (Int J Educ Integr 7, 2011) exemplary academic
integrity model, introducing “Technological Explicitness” — emphasizing the need
to include explicit guidelines about new technologies in academic integrity policies.
These results underscore the urgent need for HEIs to revise their academic integrity
policies, considering the evolving landscape of AI and its implications for academic
integrity. This paper argues for a multifaceted approach to deal with the issues of
integrating technology, education, policy reform, and assessment restructuring to
navigate these challenges while upholding academic integrity.

Keywords Academic integrity policies · Higher education institutions (HEIs) ·
Artificial intelligence (AI) tools · ChatGPT · Technological explicitness · Policy
reform

**Introduction**
The state of academic integrity at the close of 2022 presented an optimistic
picture, as instances of plagiarism, a form of academic misconduct, decreased
between 1990 and 2020 (Curtis 2022). This positive outlook was further
reinforced by the promising role of technology and educational measures in
reducing these instances (Curtis and Vardanega 2016).
However, the increasing use of advanced AI tools, notably Automated
Paraphrasing Tools (APTs) and generative-AI (Gen-AI) tools, has introduced
new complexities into this landscape. Built on large language models (LLMs)
such as GPT3.5 and GPT-4 from OpenAI and integrated into popular software
such as ChatGPT, these tools facilitate more subtle forms of plagiarism that
challenge detection methodologies (Perkins 2023; Perkins et al. 2023), sparking a
technological ‘arms-race’ in plagiarism detection (Roe and Perkins 2022).
This development coincided with a surge of interest in Gen-AI tools, leading
to an increase in AI detection tools whose efficacy is questionable, particularly
against newer LLMs or when APTs are used to alter the generated text (Sadasivan
et al. 2023). Although there is no definitive proof that the use of APTs or
Gen-AI tools by students increased during the COVID-19 pandemic, there is a
possibility that academic misconduct did rise during this period (Roe 2022). In
the post-COVID-19 era, the role of digital technology in education has become a
significant topic of discussion across various policy levels (Gašević et al. 2022),
However, despite the widespread use of digital and AI technologies, only a small
percentage of institutions have developed formal policies surrounding their use.
This highlights the pressing need for additional research on the institutional
policies related to these technologies.
In response, this empirical study offers an in-depth analysis of 142 HEIs’
publicly available academic integrity policies. We focused on the frequency of
keywords and the presence or absence of terms related to AI, APTs, and Gen-AI
tools. Employing corpus linguistics techniques — a systematic textual analysis
method that merges quantitative and qualitative approaches (Kennedy 2014)
— we seek to shed light on the stances of HEIs regarding AI technology use.
This study not only analyses the situation during the release of the ChatGPT in
November 2022, a moment that has been deemed a ‘black swan’ event (Nolan and
Ghosh 2023), but also revisits these policies 6 months later, at the end of May
1. This two-step approach allowed us to assess how prepared HEIs were for
the initial event and how quickly they adapted to the new situation, thus providing
insight into their readiness for future technological developments.
Finally, while Bretag et al.’s (2011) exemplary academic integrity policy
model serves as a useful guide for policy formulation, this study proposes
enhancements to this model based on recent technological advancements. We
suggest including a measure of ‘technological relevance’ to ensure that the model
remains responsive to the ongoing evolution of digital tools. The goal is to offer
a dynamic and future-proof framework that can effectively uphold academic
integrity in the context of a rapidly changing technological landscape.


Literature Review
New Technological Threats to Academic Integrity
Advancements in technology in recent years have significantly reshaped
numerous industries including academia. The emergence of innovative tools, such
as Automated Paraphrasing Tools (APTs) and generative-artificial intelligence
(Gen-AI) tools built on large language models (LLMs), has introduced new
possibilities for the rapid production of content that can be used to subvert
authorship expectations in an assessment scenario. A prime example is ChatGPT,
a product of OpenAI’s GPT-3.5 and GPT-4 models, which has been the subject
of extensive discussion regarding its potential influence on academic integrity
(Cotton et al. 2023; Perkins 2023; Rahman and Watanobe 2023; Rudolph et al.
2023; Uzun 2023). These Gen-AI tools can generate remarkably convincing
content that is often indistinguishable from human-authored texts, and therefore
pose significant challenges for Higher Education Institutions (HEIs), striving to
uphold academic standards and maintaining fair assessments. The sophisticated
outputs of these models further complicate the detection of AI-assisted work and
raise substantial concerns regarding the authenticity and authorship of academic
work (Abd-Elaal et al. 2022; Biderman and Raff 2022; Fröhling and Zubiaga
2021; Gunser et al. 2021; Köbis and Mossink 2021; Liang et al. 2023; Perkins
et al. 2023). APTs may be used by students to adjust the output of Gen-AI tools
to evade detection by AI text detectors and human assessors alike (Perkins et al.
2023; Sadasivan et al. 2023), or to take text that was originally human written and
adjust it so that the original source is obscured (Roe and Perkins 2022; Rogerson
and McCarthy 2017)
As these tools become more widespread and accessible, they potentially
increase the opportunities for misrepresentation and academic malpractice.
Some students may use these tools to generate essays, research papers, or other
academic assignments without proper attribution, undermining the educational
value of these tasks and the credibility of academic institutions (Perkins 2023;
Strzelecki 2023). Therefore, it is crucial for educational institutions to establish
comprehensive guidelines outlining the acceptable use of AI-generated content,
and to emphasize the importance of attribution and academic integrity (Crawford
et al. 2023; Sullivan et al. 2023).
Students may choose to use APTs or Gen-AI tools to create academic work
for many reasons, whether they are aware of the potential implications of
academic misconduct or not. One potential cause is the increased accessibility
and availability of Internet resources, which has been described as leading to a
‘cut and paste assembly line’ in the production of academic work (Warn 2006, p.
195). Furthermore, the growth of the Internet has facilitated access to tools that
assist in academic misconduct, such as the advertisement of assignment-writing
services for HE students (Crook and Nixon 2021). Such cases may represent a
starting point for the discovery of other techniques, such as APTs or Gen-AI
tools, that are more cost-effective or even free.

Text Quality and Potential for Detection
Existing research indicates that APTs can produce paraphrased text that retains a
high degree of semantic similarity (Wahle et al. 2021), which is difficult to detect by
both humans and software used to detect potential plagiarism (Wahle et al. 2022).
Although the use of the current generation APTs has the potential to be identified
because of the so-called word salad (Rogerson and McCarthy 2017) that can be
produced, the ability of Gen-AI tools to produce significantly improved paraphrases
is a significant threat to academic integrity. If LLMs are used to support more
advanced paraphrasing that avoids ‘word-salad’, then existing material accessible to
students, which posits a strong, clearly identified argument, can be paraphrased in
a way that is undetectable by both humans and software tools. Kumar et al. (2022)
also highlight how further improvements in LLMs may also lead to an increasing
prevalence of contract cheating: As commercial services take advantage of these
tools, they can increase the rate at which they are able to produce high-quality
outputs that cannot be detected as either being paraphrased from their original
source or are entirely generated by LLMs.
The recently available tools provided by OpenAI, such as ChatGPT (OpenAI
1) and DALL-E 2 (OpenAi, n.d.), have led to an explosion of interest in how
generative AI may affect academic integrity given the fluency of the created
output and its general inability to be detected, even with the aid of AI detection
tools (Perkins et al. 2023; Sadasivan et al. 2023). Although emerging evidence has
shown that there may be some cases in which techniques may be used to support
the detection of AI-generated content (Chakraborty et al. 2023; Christ et al. 2023;
Lancaster 2023), the present evidence strongly suggests that even trained academic
staff lacks the ability to consistently determine whether text is generated by a current
generation LLM or by humans (Perkins et al. 2023).
Past Exploration of Academic Integrity Policies
Academic integrity policies play a crucial role in promoting a fair and ethical
educational environment for HEIs. Previous studies on HEI academic integrity
policies have been conducted in Australia (Bretag et al. 2011; Kaktiņš 2014;
Mahmud and Bretag 2014), New Zealand (Möller 2022), Canada (Eaton 2017;
Eaton et al. 2023; Miron et al. 2021; Stoesz et al. 2019; Stoesz and Eaton 2022),
the EU (Foltýnek and Glendinning 2015; Glendinning 2013), Latvia and Lithuania
(Anohina-Naumeca et al. 2018), and Southeastern Europe (SEEPPAI 2017).
In Australia, Bretag et al. (2011) explored academic integrity policies across 39
universities, revealing inconsistencies among policies, teaching practices, decisionmaking,
and review processes. Their findings highlight an imbalance between
punitive and educative approaches to academic integrity, with many universities
lacking clear statements of institutional responsibility to uphold academic integrity
standards. Similarly, Kaktiņš (2014) explored the language used in the plagiarism
policies of Australian universities, revealing that they tended to shift from punitive

stances to more educational and pedagogical approaches, viewing students as
apprentice researchers. Regarding postgraduate research policies in Australia,
Mahmud and Bretag (2014) discovered inconsistencies with the Australian Code
for Responsible Conduct of Research and suggested a framework specifically for
postgraduate research integrity.
Examining the academic integrity landscape in New Zealand, Möller
(2022) assessed the policies of eight public universities against Bretag et al.’s
(2011) exemplary standards. The findings underscored that none of the universities
met these standards, with several needing enhancement, particularly in terms of
access and support. Canada has also emerged as a key location where academic
integrity policies have been studied. Eaton (2017) called for a more harmonized
approach among Canadian universities to maintain consistency across provinces,
while Stoesz and Eaton (2022) criticized the persistently punitive nature of academic
integrity policies and the limited support available for students and academic staff in
Western Canada. Furthermore, Stoesz et al. (2019) and Miron et al. (2021) identified
a lack of specificity for contract cheating in Ontario’s academic integrity policies
and suggested opportunities for policy development to promote academic integrity
and prevent contract cheating. Eaton et al. (2023) identify inconsistencies across
polices and also suggest an update to Bretag et al’s (2011) exemplary academic
integrity model to include an element of ‘Equity’.
The EU-wide studies conducted by Foltýnek and Glendinning (2015) and
Glendinning et al. (2013) highlight the variance in academic integrity policies and
systems across 27 countries. They utilized an academic integrity maturity model,
revealing a stark divide between Western and Eastern EU nations and identifying
the UK as having the highest score. These studies have called for concerted efforts
to bolster the existing policies and practices across the EU. Latvian and Lithuanian
policies, as explored by Anohina-Naumeca et al. (2018), indicate accessibility issues
and a lack of systematic institutional approaches to promoting academic integrity.
The Southeastern European studies by Glendinning et al. (2017) and SEEPPAI
(2017) highlighted comparable issues, where HEIs mostly fell in the lower-tomiddle
areas of academic integrity maturity.
These studies emphasize the significant variability in academic integrity policies
across different regions. The themes that have emerged underscore the need for
a more educational approach, increased support for students and staff, regular
policy reviews and updates, clear definitions, and statements of responsibility, and
directly addressing emerging threats to academic integrity. Bretag et al.’s (2011)
exemplary academic integrity policy model has been instrumental in several studies,
providing a robust basis for analysis and policy enhancement. However, no studies
have identified policies that satisfy all of the required elements of this model. The
ongoing transformations and complexities introduced by technological threats
such as APTs and Gen-AI tools require a more proactive and informed approach to
uphold academic integrity in the face of evolving challenges.
While the existing literature provides a comprehensive understanding of academic
integrity policies across various countries, a notable research gap remains in terms
of a broader understanding of how academic integrity policies are redeveloped in
the light of the new challenges brought about by technological developments. This

study fills this gap by exploring the speed at which global HEIs have adapted to the
emerging threats to academic integrity brought about by Gen-AI tools.
Method
To analyse the academic integrity policies obtained, techniques from corpus
linguistics were utilized and supplemented with inductive content analysis. Corpus
techniques are used to study large amounts of data and allow researchers to combine
quantitative techniques with in-depth qualitative analyses of large bodies of texts
(Freake et al. 2011). A specialized corpus was compiled based on the gathering
of publicly available academic integrity policy documents from the HEIs. To gain
a balanced view of policies worldwide, a two-pronged strategy was undertaken
to achieve a balanced corpus that represented leading institutions in the field of
academic integrity. To achieve this aim, we initially focused on the Quacquarelli
Symonds (QS) world university rankings as the most widely read university
ranking system. QS rankings place 40% of their weight on academic reputation,
making the listing highly competitive and representative of the perceived quality
of the institution (QS 2022). First, the academic integrity policies were taken from
the online websites of the top ten universities on the Quacquarelli Symonds (QS)
rankings from six geographical regions: Africa, Oceania, Europe, North America,
Latin America, and Asia. In the event that missing data (as in several regions)
or policies were unavailable in English, we extended the search to the top 15
institutions in each region. Following this, we expanded the corpus by focusing on
the university policies of HEIs, which are strongly engaged in the field of academic
integrity. This was achieved by collecting policies from HEIs that held membership
in either the European Network of Academic Integrity (ENAI) or the International
Center for Academic Integrity (ICAI). ENAI is a membership-based institution
that aims to develop a culture of academic integrity, both in Europe and around the
world, with 92 member institutions across Europe, Central Asia, India, and North
America. The ICAI, founded by the academic integrity specialist Don McCabe in
1992, is credited with developing the six fundamental values of academic integrity
on which many HEI policies are built, including 91 listed member organizations,
of which 58 are based in the US, 18 are Canadian, and the remainder come from
various countries, including Central Asia, Europe, South America, North Africa,
and the Middle East (ICAI n.d.).
The inclusion criteria were as follows: First, institutions had to be a HEI, and
have a clearly accessible overarching academic integrity policy. By overarching, we
mean that the policy was at the university-wide level, rather than belonging to a
specific school, discipline, or programme, as initial web searches revealed multiple
policies for different schools under the heading of each institution. Furthermore,
policies had to be publicly available online, in the English language, and describe
specific policies for the definition and violations of academic integrity or
committing to academic misconduct. Pilot searches revealed that terminology varied
greatly among institutions, so multiple searches were undertaken using a range of
single- and multi-word terms including ‘honor code’, ‘academic misconduct policy’,

‘academic integrity policy’, ‘student code of conduct’, ‘plagiarism policy’, and
‘cheating policy’.
The way policies were communicated varied, from a downloadable PDF
document to a website that combined policy details with educational multimedia,
such as videos, quizzes, and links to external organizations, such as ICAI. In
these cases, pages (s) that best fit our aim of capturing the detailed policies to be
communicated to students were selected for inclusion in the corpus.
The initial period of data collection was carried out between 29/11/2022-
09/12/2022, with the release of ChatGPT by OpenAI occurring on November 30,
1. Beginning with the search for the top 10 QS-ranked HEIs in the African
region, three of the top 10 HEIs in the QS rankings did not have a publicly available
policy. Extending the search to the top 15 HEIs resulted in the collection of required
numbers. In Oceania, Europe, and North America, every HEI in the top ten QS
rankings had a publicly available policy. In Latin America, no publicly available
policies were found in English even when the search was extended to the top 15
institutions. After extending the search to the top 15 institutions, ten policies were
found in the Asia region. This resulted in 47 policy documents being collected from
the QS rankings. For ENAI member institutions, it was determined that 7 of the 42
members were not HEIs and thus were excluded from the study. Of the remaining
35 institutions, 20 had publicly available academic integrity policy documents.
Of the 91 ICAI member institutions, three were not classified as HEIs, and one
was included in the ENAI search as a member of both networks. Fifteen member
institutions did not have accessible policies, resulting in 72 policy documents
collected from the ICAI. In total, 142 academic integrity policy documents were
collected (Table 1). These were then collated and compiled into a corpus using
Sketch Engine with 699,738 words.
Throughout the process of collecting the policies for compilation, we undertook
familiarization with the data, an important step in enriching the analysis process
and developing greater insight, given that a corpus once compiled is essentially
decontextualized (Baker 2006). The corpus was compiled using Sketch Engine,
a fourth-generation corpus analysis tool designed for multidisciplinary use
(Sketch Engine 2016). Sketch Engine allows for case-insensitive searching and

automatically marks up text, meaning that manual processing is not required (Sketch
Engine 2016). Subsequently, we performed a keyword analysis. Keyword analysis
can indicate the aboutness of texts contained in a corpus by comparing the content
to a reference corpus. In this case, the enTenTen corpus, which contains 36 billion
words in English across multiple genres, was used. Keyword analysis was performed
using the statistical measures offered in the native Sketch Engine interface. We
retained the content words, while grammatical words that indicated style rather than
aboutness (Baker, 2004) were discarded. Following keyword analysis, we undertook
exploratory searches for a range of search terms related to artificial intelligence,
ChatGPT, LLMs, and APTs to determine their presence or absence in the corpus.
After this initial phase, we returned after a period of six months to compare
our findings and identify whether policies had changed in the light of the
significant impact on academic integrity caused by the release of and subsequent
worldwide interest in generative-AI tools, namely ChatGPT. Between 30/05/2023
and 31/05/2023, all 142 HEIs for which we obtained academic integrity policies
were reviewed to determine whether any changes had been made to the academic
integrity policies. Based on the lack of identified changes in any of the initially
collected policy documents, we collected supplementary web pages and documents,
which had been produced by HEIs, providing guidance to faculty and students on
AI, and built a second corpus using these documents to conduct a keyword analysis.
Following this, we conducted an inductive content analysis of the second corpus to
identify the themes and categories in these supplementary documents.
Results
November 2022 Corpus
After adjusting for prepositions, proper nouns, and other grammatical words, the top
ten keywords in the first corpus were as follows:
1. Plagiarism 6. Plagiarize
2. Misconduct 7. Disciplinary
3. Dishonesty 8. Cheating
4. Integrity 9. Turnitin
5. Academic 10.Pre-Requisite
Both ‘plagiarism’ and ‘misconduct’ feature are the most ‘key’ single word terms
of the corpus. Looking more broadly at the results, it is possible to draw on the
notion of the ‘semantic field’, a metaphor, which describes the types of objects,
which are contained within it; for example, a legal semantic field would contain
commonly found legal terms such as ‘prison’, ‘investigation’, and ‘trial’ (Morley and
Partington 2009). The semantic field when looking at the frequency and keyword
analysis results suggests a focus on rules, discipline, and unacceptable behaviour
(i.e. misconduct, cheating, and plagiarism).

In the results of the keyword analysis, both ‘plagiarism’ and ‘misconduct’ feature
are the most ‘key’ single word terms of the corpus. The keyword analysis reveals
that the main topics or ‘aboutness’ (Baker 2004) of the corpus relate to acts of
misconduct and dishonesty. The keyword analysis states that plagiarism is the most
‘key’ term, indicating a focus on plagiarism as opposed to other forms of academic
misconduct. Interpreting this result gives the impression that textual plagiarism
requires the most attention. ‘Turnitin’ also appeared as a common keyword, which
further strengthens that such policies in aggregate focus on textual plagiarism more
than other forms of misconduct, given that Turnitin primarily acts as a text-matching
software.
Following this, we conducted search queries within the corpus for AI-related
terminology, including GPT-3, which was the most advanced version of ChatGPT’s
operating LLM at the time of data collection. The results of this study are
summarized in Table 2.
Across all regions and policies (bar 1), the absence of clarity regarding AI and
associated tools was clear. Only one of the 142 surveyed institutions mentioned
AI and APT usage and provided a policy on how these tools should be used. This
policy, upon further investigation, was updated in 2021, demonstrating that the
institution had recognized the threat and instituted formal policies to consider these
issues at a relatively early stage and over a year prior to the release of ChatGPT.


Regarding APTs, the term ‘Paraphrasing’ occurred frequently in the corpus, being
mentioned in 48 policies. The mention of paraphrasing in many of these instances
describes how paraphrasing should be used to avoid being accused of plagiarism.
While several policies described the risks of close paraphrasing and patchwriting,
in which only minor amounts of content or words were changed or substituted,
only one policy mentioned the prohibition and risk of using paraphrasing tools
to automatically modify text, and one policy mentioned the use of article and
text spinners (a form of APT). While translation was mentioned by five policies,
machine-translated texts were not mentioned. However, there are clear and abundant
mentions of the prohibited practices. The search terms ‘third parties’, ‘contract
cheating’, and ‘collusion’ all featured frequently in the corpus. It could be argued
that such sentences by their nature cover LLMs and AI tools, given that they are
technically ‘third parties’. On the other hand, student writers may misinterpret this,
especially given that even aside from the dilemma of when a software may constitute
an actor or person capable of being a ‘third party’, research demonstrates students
and faculty are unclear on and disagree on what constitutes plagiarism (Belter and
du Pré 2009; Dawson and Overfield 2006; Ramzan et al. 2012; Roig 1997, 1999,
2001).
Follow‑up May 2023 Corpus
Following a 6 months interval, we returned to each of the HEIs websites to identify
whether the academic integrity policies had been updated or renewed in the light
of the release of ChatGPT, Bard, and other Gen-AI tools. The original intention
for this study was then to create a secondary corpus with the updated policies and
rerun the analysis, while also looking at granular detail at concordance lines, which
featured ‘AI’, and ‘ChatGPT’. However, upon returning to the HEI websites, we
found that none of the 142 institutions had updated their policies. That said, during
our data collection, we noticed that many institutions launched specific pages and
documents to provide information on Gen-AI tools for both students and faculty.
We decided to collect these guidance pages and broaden our search to include all
pages that specifically referenced artificial intelligence, ChatGPT, and Gen-AI tools
in relation to student and teacher use in academic work. This led to the collection
of 53 webpages and documents from 53 HEIs. Twenty-seven of the 53 documents
came from institutions in the USA, and 11 from institutions in Australia. Other
contributions came from institutions in Canada (8), Africa (3), Europe (3), and
the Middle East (1). When a corpus was created using this documentation, it was
comprised of 29,376 words.
While the texts in this secondary corpus are, by nature, not policy documents, we
decided that running a keyword analysis would provide an opportunity to see how
AI concerns are framed by official institutional guidance or advice. We conducted
keyword analysis, and after adjusting for prepositions, proper nouns, and other
grammatical words, the top ten keywords were as follows:

The results of the keyword analysis revealed a significant focus on ChatGPT, a
specific product of OpenAI. A frequency search revealed that ChatGPT is mentioned
337 times within this corpus, whereas other Gen-AI tools, such as Google’s Bard,
are not mentioned at all. The keyword ‘plagiarism’ indicates that the key concern of
such informational pages is to provide information on how such tools can be used
for this purpose. This is furthered by the focus on ‘integrity’ and ‘honesty’. This
suggests that there may be a closer focus on how generative-AI technologies can be
used for misconduct rather than how they can support and improve learning. Further
analysis was deemed necessary at a more granular level; therefore, content analysis
was chosen.
We undertook an inductive manifest thematic content analysis of the 52
documents, taking the content at face value (Kleinheksel et al. 2020) and following
the thematic content analysis procedures of ‘low hovering’ over the data, as
described by Anderson (2007). Structurally, we followed the example of Kyngäs
(2020), focusing on data reduction followed by data grouping and concept formation
through open coding. We followed the structure outlined by Kyngäs (2020), focusing
on data reduction, followed by data grouping, and the formation of concepts through
open coding. Five categories were developed to describe the general approach that
these guidance pages adopted to inform readers about their approach to generative
AI. The results are presented in Table 3.
These five macro-categories of thematic expressions were found to be highly
relevant to the AI documents provided by HEIs. Overwhelmingly, the tone and
approach taken towards Gen-AI was one of optimism and encouragement. The
documents referenced the importance of embracing technology in learning and
assessment for both the faculty and students. This contrasts directly with the expected
results from the keyword analysis. The focus of keywords on academic integrity **and**



