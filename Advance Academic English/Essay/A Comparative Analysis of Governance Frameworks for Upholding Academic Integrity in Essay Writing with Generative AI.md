### Introduction

#### Background
Generative AI tools like OpenAI’s ChatGPT have rapidly entered the academic scene, raising new questions about academic integrity in essay writing. Launched in late 2022, ChatGPT can produce coherent essays within minutes ([The Benefits, Risks and Regulation of Using ChatGPT in Chinese Academia: A Content Analysis](https://www.mdpi.com/2076-0760/12/7/380#:~:text=popularized%20worldwide%20rapidly%20,an%20act%20of%20cheating%20that)), blurring the line between a student’s own work and AI-generated content. Its uptake among students has been swift: for example, a recent survey in China found nearly 60% of university faculty and students use generative AI at least weekly, with about 30% of students relying on AI to help write assignments ([Chinese universities tighten AI usage rules to curb academic misuse](http://www.ecns.cn/news/cns-wire/2025-02-27/detail-ihepcskv6108382.shtml#:~:text=A%20survey%20by%20MyCOS%2C%20an,a%20CCTV%20news%20portal%20reported)). In the United States, an informal poll at Stanford University similarly revealed a significant number of students admitted to using ChatGPT for final assessments ([](https://en.front-sci.com/index.php/rerr/article/view/2164/2368#:~:text=research%20,constitutes%20academic%20misconduct%20is%20currently)). This widespread adoption underscores the pressing need to address how such tools can be used ethically. Educational institutions now face the challenge of preserving academic honesty when students have access to AI that can generate passable (even excellent) essays on demand.

#### 

The rapid proliferation and widespread adoption of generative artificial intelligence (GenAI) have significantly disrupted higher education (HE) institutions globally, presenting transformative challenges and prompting fundamental questions about existing academic practices (Hughes et al., 2025). While offering potential benefits like personalized learning experiences and automating certain tasks (Hughes et al., 2025, p. 2), GenAI simultaneously poses considerable challenges to academic integrity, forcing the academic community to re-evaluate traditional methods and standards (Dwivedi et al., 2023, cited in Hughes et al., 2025).

Academics express widespread concerns regarding GenAI's impact, including the potential undermining of critical thinking, the lowering of academic standards, and threats to established academic models (Hughes et al., 2025, Abstract). A central issue revolves around plagiarism and academic misconduct. Students submitting AI-generated text as their own work directly contravenes the principle of original scholarship (The Benefits, Risks and Regulation of Using ChatGPT in Chinese Academia). This misuse represents a real threat to learning, teaching, and research integrity (Hughes et al., 2025, p. 4). Detection is a significant hurdle, as the output from tools like ChatGPT is often fluent, well-structured, and capable of creating content nearly indistinguishable from human writing, making stylistic analysis an unreliable detection method (AI makes plagiarism harder to detect; Hughes et al., 2025, p. 4).

Compounding this, the reliability of GenAI outputs itself is a major concern impacting academic integrity. AI systems are known to "hallucinate," fabricating sources and citations that appear realistic but are non-existent (AI makes plagiarism harder to detect; Hughes et al., 2025, p. 11, Table 3). Outputs can also be overly general, lacking the necessary academic depth and scientific rigor (Hughes et al., 2025, p. 11, Table 3). This jeopardizes the foundation of academic work, potentially embedding false evidence that evades standard checks and undermining the credibility of research and scholarship (Hughes et al., 2025, p. 5).

Beyond direct plagiarism and data fabrication, educators worry about the impact on student learning and skill development. Over-reliance on GenAI tools may hinder students' learning experiences by replacing opportunities for critical thinking, analysis, and writing skill development with automated solutions (Hughes et al., 2025, p. 3; [Original Review Source]). If students bypass the essential cognitive effort involved in academic writing, they risk not developing these crucial skills, potentially leading to a "de-skilling" of graduates (Hughes et al., 2025, p. 4). Furthermore, ethical considerations extend to data privacy, algorithmic bias, and the lack of transparency concerning LLM training data and platform regulation, often controlled by a few powerful entities (Hughes et al., 2025, p. 5). Issues of equity also arise, as unequal access to sophisticated GenAI tools could widen the digital divide and exacerbate existing educational inequalities (Hughes et al., 2025, p. 4).

In summary, the advent of generative AI introduces multifaceted challenges to academic integrity, particularly in academic writing. It enables new forms of academic misconduct, from sophisticated ghostwriting to the use of fabricated data, while also raising fundamental questions about the learning process, skill development, assessment validity, research reliability, and equity. Existing academic integrity policies and assessment methods are struggling to keep pace with the rapid evolution and capabilities of these technologies (Hughes et al., 2025; [Original Review Source]), necessitating urgent strategic reflection and adaptation within higher education institutions.